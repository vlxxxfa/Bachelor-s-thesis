\chapter{Theorie}
\section{Skalierbarkeit und Wartbarkeit}
%\section{\colorbox{green}{Skalierbarkeit und Wartbarkeit}}

In diesem Kapitel wird der Begriff \textit{Skalierbarkeit} erklärt sowie die notwendigen Kompromisse erläutert, die bei der Entwicklung einer verteilten skalierbaren Anwendung eingegangen werden müssen. Das \textbf{CAP-}Theorem beschreibt die Grenzen eines verteilen Systems und \textbf{BASE} fasst größtmögliche Anforderungen an ein verteiltes System zusammen. Danach werden die \textit{Best Practices} und \textit{Patterns} beschrieben, deren Einhaltung die Entwicklung einer modulären Webanwendung mit austauschbaren Komponenten ermöglicht. 

%\subsection{\colorbox{green}{Skalierbarkeit}}\label{scale}
\subsection{Skalierbarkeit}\label{scale}
Der Begriff \textit{Skalierbarkeit} \cite{node} beschreibt die Fähigkeit eines Systems, aufgrund der wachsenden Anforderungen, entweder die Leistung der vorhandenen Ressourcen zu verbessern oder zusätzlich die neuen Ressourcen hinzufügen. %Das System, bei dem die neuen Ressourcen hinzugefügt werden, nennt man \textit{verteilte Systeme}.

Bei der Skalierung sind zwei Arten zu unterscheiden, eine \textit{vertikale} und eine \textit{horizontale Skalierung}, die demnächst näher erläutert wird.

\subsubsection{Vertikale Skalierbarkeit}
%\subsubsection{\colorbox{green}{Vertikale Skalierbarkeit}}

Die \textit{vertikale Skalierbarkeit (scale-up)} strebt eine qualitative Steigerung der Leistungsfähigkeit an, bei der die bereits eingesetzten Ressourcen, beispielsweise durch die Speichererweiterung oder CPU-Steigerung, verbessert werden.

Die vertikale Skalierbarkeit hat den Vorteil, dass die Daten nicht verteilt werden müssen. Die Nebenläufigkeit kann mit \textit{Threads} realisiert werden. Jedoch hat die vertikale Skalierbarkeit ihre Grenzen - ein Rechner kann nicht endlos vergrößert werden. 

\subsubsection{Horizontale Skalierbarkeit}
%\subsubsection{\colorbox{green}{Horizontale Skalierbarkeit}}

Im Gegensatz zur vertikalen Skalierung wird bei der \textit{horizontalen Skalierbarkeit (scale-out)} die Last auf zusätzliche Rechner verteilt. Die Anwendung wird auf einem verteilten System (Cluster) ausgeführt. In dem verteilten System können mehrere weniger leistungsfähige, nicht so teuere Rechner eingesetzt werden. Die Daten müssen auf die Knoten im Cluster verteilt werden und bei manchen Anwendungen ist die Synchronisation der Zwischenergebnissen notwendig. Dabei entstehen zusätzliche Kommunikationskosten, weil die Kommunikation per Netzwerk viel teuerer ist als Lesen vom Arbeitsspeicher. Deswegen wäre es falsch, die zusammengesetzte Leistung eines Clusters mit Leistung eines leistungsstarken Rechners zu vergleichen. Jedoch kommt es immer auf die Anwendung an, wie viel davon überhaupt parallelisierbar und wie viel Synchronisation notwendig ist. Ein Cluster kann sehr groß werden und wenn auch jeder zusätzlicher Core in dem Cluster nicht so viel bringt im Vergleich zu dem, was ein zusätzlicher Core in einer Applikation auf einem Rechner bringen würde, dadurch dass es im Cluster viel Ressourcen verfügbar sind, können die Applikationen besser skalieren.

%Im Gegensatz zur vertikalen Skalierung verteilt die \textit{horizontale Skalierbarkeit (scale-out)} die Daten auf verschiedenen Knoten im großen Cluster, wobei die quantitative Steigerung der Leistungsfähigkeit angestrebt wird. Somit können mehrere weniger leistungsfähige, nicht so teuere Rechner eingesetzt werden.
Allerdings unterscheidet sich die Entwicklung eines verteilten Systems von den klassischen Anwendungen, die auf einer Maschine laufen, da die Daten in dem Cluster verteilt sind. Die \textit{Trade-offs} einer verteilten Anwendung wurden bereits in der CAP-Theorem formalisiert.

%\subsubsection{ACID-Prinzip}\label{acid}
\subsubsection{\colorbox{red}{ACID-Prinzip}}\label{acid}

Des Weiteren sind sinnvolle Regeln zum effektiven und effizienten Umgang mit Transaktionen unvermeidbar. Solche Regeln sind in einem \acid\ definiert.

\textbf{ACID} steht für \Acid, \aCid, \acId\ und \aciD\ und beschreibt somit die Eigenschaften eines Datenbankmanagementsystems zur Sicherung der Datenkonsistenz bei Transaktionen.
\begin{itemize}

\item \Acid: Die \textit{Atomarität} einer Transaktion bedeutet, dass sie entweder ganz oder gar nicht ausgeführt wird. Falls eine Transaktion abgebrochen wird, werden alle im Laufe der Transaktion schon durchgeführte Änderungen rückgängig gemacht, um Konflikte mit der Ausführung neuer Transaktionen zu vermeiden.%was eigentlich zu einer sicheren Fehlerisolierung führt.
\item \aCid: Die \textit{Konsistenz} besagt, dass vor und auch nach dem Ablauf einer Transaktion die Integrität und Plausibilität der Datenbestände gewährleistet werden. Die Integrität der Datenbank ist es möglich, beispielsweise mit Integritätsbedingungen\footnote{Unter Integritätsbedingungen (Zusicherungen, Assertions) sind Bedingungen zu verstehen, die die Korrektheit der gespeicherten Daten sichern. Diese werden in SQL zum Beispiel mithilfe von CONSTRAINTS formuliert. Folgende CONSTRAINTS sind möglich: NULL, NOT NULL, PRIMARY KEY, FOREIGN KEY etc.} zu gewährleisten. 
%Diese werden bis zur abgeschlossenen Transaktion in einem konsistenten Zustand gehalten und werden bei der Transaktion in einen anderen konsistenten Zustand überführt.
\item \acId: Die \textit{Isolation} dient zu Kapselung von Transaktionen, um unerwünschte Nebenwirkungen vermeiden zu können. Die Transaktionen müssen unabhängig voneinander ablaufen.
\item \aciD: Die \textit{Dauerhaftigkeit} gewährleistet nach einer erfolgreichen Transaktion die Persistenz aller Datenänderungen. Im Falle eines Systemfehlers oder Neustarts müssen die Daten nichtsdestotrotz zur Verfügung stehen, dass sie in einer Datenbank dauerhaft gesichert sein müssen.
%dauerhaft in der Datenbank zu erhalten.
%Genauer gesagt, die Daten müssen dauerhaft auf einem Datenträger gesichert sein
\end{itemize}

\subsubsection{Das CAP-Theorem}\label{cap}
%\subsubsection{\colorbox{green}{Das CAP-Theorem}}\label{cap}

Im Jahr 2000 präsentierte Eric A. Brewer das \textbf{CAP}-Theorem - ein Ergebnis seiner Forschungen zu verteilten Systemen. Das Ergebnis zeigte, dass bei den verteilten Systemen alle drei folgenden Anforderungen wie \Cap, \cAp\ und \caP\ gleichzeitig nicht zu erfüllen sind.
%\colorbox{yellow}{Im Jahr 2000} hielt Brewer\footnote{Eric A. Brewer ist ein Informatik-Professor an der University of California, Berkeley und einer der Erfinder der Suchmaschine Inktomi} die Keynote auf dem ACM Symposium on Principles of Distributed Computing (PODC)\footnote{PODC2000: \url{http://www.podc.org/podc2000/}, zugegriffen am 02.01.2017}, einer Konferenz über die Grundlagen der Datenverarbeitung in verteilten Systemen\footnote{In einem verteilten System im Bereich Datenverarbeitung werden gespeicherte Daten mehrfach über mindestens zwei verschiedene Server repliziert und miteinander synchronisiert, um die Verfügbarkeit der Daten zu erhöhen und die Zugriffszeiten der User zu verringern.} (Principles of Distributed Computing).  In seiner Keynote stellte Brewer sein \textbf{CAP}-Theorem vor, ein Ergebnis seiner Forschungen zu verteilten Systemen an der University of California \cite[S. 13]{Kurowski.2012}. Brewer's Theorem wurde im Jahr 2002 von Seth Gilbert und Nancy Lynch formal bewiesen.
\begin{figure}[H]
\centering
\includegraphics[trim = 0mm 189mm 0mm 9mm, clip, width=1.0\textwidth]{resources/myPictureForCAP}
\caption[\textbf{CAP}-Theorem]{Anforderungen an verteilte Systeme gemäß dem \textbf{CAP}-Theorem}
\label{img:cap}
\end{figure}

Das Akronym \textbf{CAP} steht für die englischsprachigen Begriffe  \Cap, \cAp\ und \caP. Diese sind mögliche Anforderungen an eine verteilte Anwendung.
\begin{itemize}
\item \Cap: Diese Anforderung ist erfüllt, wenn nach Abschluss einer atomaren\footnote{Eine atomare Transaktion bedeutet, dass sie entweder ganz oder gar nicht ausgeführt wird. Falls eine atomare Transaktion abgebrochen wird, werden alle im Laufe der Transaktion bereits durchgeführte Änderungen rückgängig gemacht.} Transaktion (oder Interaktion mit dem System) nicht nur die manipulierenden Datensätze, sondern auch alle replizierenden Knoten in einem großen Cluster über die gleichen Daten verfügen. Wenn ein Wert auf einem Knoten geändert wird und die Interaktion mit dem System abgeschlossen wird, muss der aktualisierte Wert von anderen Knoten zurückgeliefert werden können. Dies hat zur Folge, dass ein System erst dann die Interaktion abschließen darf, wenn sichergestellt ist, dass die Änderungen auf alle Datenkopien angewendet wurden. Für die verteilten Systeme, die Daten replizieren, resultiert es in langen Antwortzeiten für die Schreiboperationen.

\item \cAp: Die \textit{Hochverfügbarkeit} ist eine weitere Anforderung, die besagt, dass immer alle gesendeten Anfragen durch User an das System mit einer akzeptablen Reaktionszeit beantwortet werden müssen.

\item \caP: Die \textit{Partitions- oder Ausfalltoleranz} bedeutet, dass der Ausfall eines Knoten bzw. eines Servers aus einem Cluster das verteilte System nicht beeinträchtigt und es weiterhin fehlerfrei funktioniert. Falls einzelne Knoten in so einem System ausfallen, wird deren Ausfall mit den verbleibenden Knoten aus dem Cluster kompensiert, um die Funktionsfähigkeit des Gesamtsystems aufrecht zu halten.

\end{itemize}

Die graphische Darstellung für das Brewer's \textbf{CAP}-Theorem ist aus der Abbildung \ref{img:cap} zu entnehmen. Wie die Abbildung \ref{img:cap} erkennen lässt, können in einem verteilten System gleichzeitig und vollständig nur zwei von drei Anforderungen  \Cap, \cAp, \caP\ erfüllt werden. Konkret aus der Praxis bedeutet das, dass es für eine hohe Verfügbarkeit und Partitions- oder Ausfalltoleranz notwendig ist, die Anforderungen an die Konsistenz zu lockern \cite[S. 31]{Edlich.2011}.

Die Anforderungen in Paaren klassifizieren gemäß dem \textbf{CAP}-Theorem bestimmte Datenbanktechnologien. Für jede Webanwendung muss daher individuell entschieden werden, ob sie als ein \textbf{CA-}, \textbf{CP-} oder \textbf{AP-}System zu realisieren ist.
\begin{itemize}
\item \textbf{CA} (\textbf{C}onsistency und \textbf{A}vailability): Die klassischen relationalen Datenbankmanagementsysteme (RDBMS) wie Oracle, DB2 etc. fallen in \textbf{CA}-Kategorie, die vor allem auf  \Cap\ und \cAp\ aller Knoten in einem Cluster hinzielen. Hierbei werden die Daten nach dem \textbf{ACID}-Prinzip verwaltet. Die relationalen Datenbanken sind für Ein-Server-Hardware konzipiert und vertikal skalierbar. Das bedeutet, dass solche Systeme mit hochverfügbaren Servern betrieben werden und \caP\  nicht unbedingt in Frage kommt.

%\begin{itemize}
%\item keine Partitionstoleranz
%\item (Relationale) Datenbank ermöglicht verteilte Transaktionen zur Konsistenzwahrung
%\item Voraussetzung: funktionierendes Netzwerk (kein Nachrichtenverlust)
%\item URL: \url{http://dbs.uni-leipzig.de/file/NoSQL_SS14_01_Intro.pdf}
%\end{itemize}

\item \textbf{CP} (\textbf{C}onsistency und \textbf{P}artition tolerance): Ein gutes Beispiel für die Webanwendungen, die zu der \textbf{CP-}Kategorie zuzuordnen sind, sind Banking-Anwendungen. Für solche Anwendungen ist es wichtig, dass die Transaktionen zuverlässig durchgeführt werden und der mögliche Ausfall eines Knotens verschmerzt werden kann. 
%
%\begin{itemize}
%\item keine Verfügbarkeit
%\item im Falle von Netzwerkpartitionierung werden Transaktionen blockiert
%\item Vermeidung möglicher Konflikte bei Merge, dadurch Sicherstellung der Konsistenz
%\item URL: \url{http://dbs.uni-leipzig.de/file/NoSQL_SS14_01_Intro.pdf}
%\end{itemize}

\item \textbf{AP} (\textbf{A}vailability und \textbf{P}artition tolerance): Für die Anwendungen, die in die \textbf{AP-}Kategorie fallen, rückt die Anforderung \Cap\ in den Hintergrund. Beispiele für solche Anwendungen sind die Social-Media-Sites wie Twitter oder Facebook, da die Hauptidee der Anwendung nicht verfällt, wenn zum gleichen Zeitpunkt die replizierten Knoten nicht die gleiche Datenstruktur aufweisen. 
\end{itemize}
%
%\begin{itemize}
%\item keine Konsistenz
%\item Writes stets möglich auch wenn keine Kommunikation mit anderen Knoten möglich
%(z.B. Synchronisation)
%\item Notwendigkeit der Auflösung inkonsistenter Daten, d.h. verschiedene Versionen des
%selben Datums an verschiedenen Knoten
%\item URL: \url{http://dbs.uni-leipzig.de/file/NoSQL_SS14_01_Intro.pdf}
%\end{itemize}

\subsubsection{Das BASE-Prinzip}\label{base}
%\subsubsection{\colorbox{green}{Das BASE-Prinzip}}\label{base}

\textbf{BASE} steht für \BAse, \baSe, \basE\ und beschreibt eine Alternative zu den strengen \textbf{ACID}-Kriterien.
Bei den Systemen, die nach dem \textbf{BASE}-Prinzip gestaltet sind, wird bewusst in Kauf genommen, dass die Daten nach Schreiboperationen eine absehbare Zeit inkonsistent sein können.

Bei solchen Systemen ist viel mehr die permanente Verfügbarkeit des Systems für die Clients wichtig, als die Möglichkeit, die gleichen Daten zu dem sofortigen Zeitpunkt zu sehen. Nach Ablauf einer gewissen Zeit muss das System den inkonsistenten Zustand der Daten wieder in einen konsistenten Zustand bringen, so dass alle Clients die gleichen Daten sehen können \cite{base}.

\begin{itemize}
\item \BAse\ bedeutet, dass ein System immer verfügbar ist und eine Antwort immer zurückkommt. Die gelieferten Daten müssen nicht konsistent sein. Es können inzwischen Updates geben, die zwar den Datenstand geändert haben, allerdings mit dem Knoten, der geantwortet hat, noch nicht synchronisiert wurden.

\item \baSe\ kennzeichnet, dass der Datenzustand nicht unbedingt alle Updates abbildet, die bisher eingegangen sind. Es können Updates geben, die noch nicht überall angewendet wurden.

\item \basE\ besagt, dass sich das System in einem konsistenten Zustand befindet, wenn alle eingegangenen Update-Operationen auf den Daten überall angewendet wurden und keine neuen Daten zwischenzeitlich eingegangen sind.\cite{acidVSBase}
\end{itemize}

\subsection{Wartbarkeit}\label{maintenance}
%\subsection{\colorbox{green}{Wartbarkeit}}\label{maintenance}

Um die Wartungs- und Erweiterungsfähigkeiten von der Software zu gewährleisten, sollen die grundlegenden Designprinzipien eingehalten werden.

\subsubsection{Die SOLID-Prinzipien}\label{solid}
%\subsubsection{\colorbox{green}{Die SOLID-Prinzipien}}\label{solid}

Das von Martin Fowler geprägtes Akronym \textbf{SOLID}\cite{solid} steht für fünf Prinzipien des objektorientierten Designs. Bei korrekter Anwendung dieser Prinzipien erfolgt eine höhere Wartbarkeit am Softwareprodukt. Die Software, die mit der Einhaltung von \textbf{SOLID} Regeln entwickelt wird, besteht aus vielen kleinen Modulen. Jedes Modul übernimmt bei der Entwicklung eine klare Funktion und die Interaktion zwischen diesen Modulen erfolgt über die explizit definierten Schnittstellen.

Im Einzelnen beschreibt \textbf{SOLID} folgende Regeln:

\begin{itemize}

\item \textit{\textbf{S}ingle responsibility principle} - Eine Klasse (oder Modul) soll nur eine bestimmte Funktion abdecken und eine Funktion soll von einer Klasse implementiert werden. Martin Fowler \cite{MartinFowler} nach, kann es für die Änderung einer Klasse nur einen Grund geben. Im Kontext der Prototypanwendung könnte der Backend-Teil beispielsweise zwei Funktionen haben, die Bearbeitung von Frontend-Anfragen und Verwaltung der Daten in der Datenbank. Demnach wäre das Design schlecht, wenn eine Klasse beide diese Funktionalitäten implementieren würde. In diesem Fall gäbe es mehrere Gründe für die Änderung dieser Klasse - z. B. eine Änderung in Kommunikation mit Frontend oder in der Datenhaltung.

\item \textit{\textbf{O}pen/closed principle} - Die Klassen/Module sollen für die Erweiterung offen sein, die bestehenden Klassen sollen jedoch nicht geändert werden. Die Idee, die dahinter steht, kann folgendermaßen zusammengefasst werden. Sofern die neuen Funktionalitäten eingeführt werden, darf der bestehende Code nur minimal geändert werden. Beispielsweise wurden die Daten der Foto-Verwaltungs-Anwendung bisher in der relationalen Datenbank abgelegt und zusätzlich soll die Datenhaltung in der NoSQL-Datenbank implementiert werden. Die NoSQL-Datenhaltung soll in eigenem Modul implementiert werden, dadurch darf die Codebasis für die Interaktion mit relationaler Datenbank nicht geändert werden. 

\item \textit{\textbf{L}iskov substitution principle} - Die Subklassen dürfen das Verhalten der Elternklassen nicht ändern. Der Code, der auf bestehenden Funktionen der Elternklassen aufgebaut ist, muss auch mit Subklassen fehlerfrei funktionieren.

Wenn z. B. die Foto-Verwaltungs-Anwendung erweitert wird und z. B. die Videos verwaltet werden sollen, wäre es falsch, die Klasse \textit{`Video`} aus der Klasse \textit{`Foto`} abzuleiten, weil Videos andere Eigenschaften als Bilder haben.

\item \textit{\textbf{I}nterface-segregation principle} - Die Interfaces sollen so klein wie möglich sein und nur einzelne Funktionen abdecken.

\item \textit{\textbf{D}ependency inversion principle} - Die Abhängigkeiten zwischen Modulen sollen über Abstraktionen \textit{(Interfaces)} gekoppelt werden. Ein Modul soll eine direkte Abhängigkeit zu den anderen Modulen vermeiden, die Abhängigkeiten werden zu den Interfaces definiert. Demzufolge können die Module die Interfaces implementieren und ohne großen Aufwand ausgetauscht werden. 

Für die Module sind nur die Interfaces sichtbar, die zu implementieren sind. Es können keine Annahmen getroffen werden, welche Teile der Anwendung diese Module verwenden werden. Sie sollen überall einsetzbar sein, wo sie ihre Funktion, die in dem Interface definiert ist, erfüllen können. Als Beispiel wird erneut Backend der Foto-Verwaltungs-Anwendung genommen und die Interaktion zwischen dem \textit{Service}-Modul betrachtet, das mit Frontend interagiert und dem Modul, das Daten in der relationalen Datenbank verwaltet. Anstatt eine Referenz zu diesem spezifischen Datenbankmodul zu deklarieren, wird eine Referenz zu einem Interface deklariert, das die Datenhaltungskomponente beschreibt. Aus der Sicht des \textit{Service}-Moduls gibt es eine Menge von notwendigen Operationen zum Speichern oder zum Abrufen der Daten. Diese Operationen sind unabhängig von der Art der Daten ähnlich aufgebaut und deswegen werden sie in einem \textit{Interface} zusammengefasst. Das \textit{Service}-Modul deklariert eine Abhängigkeit zu diesem \textit{Interface}. Dieses \textit{Interface} kann von verschiedenen Datehaltungskomponenten implementiert werden.

\end{itemize}

\subsubsection{Dependency Injection (DI)}\label{di}
%\subsubsection{\colorbox{green}{Dependency Injection (DI)}}\label{di}

\textit{Dependency Injection} \cite{DIEinfuehrung} ist der nächste Schritt nach \textit{Dependency Inversion}. Das \textit{Dependency Injection Pattern} basiert auf dem \textit{Inversion of Control Konzept} \cite{MartinFowlerTwo}. Das bedeutet, dass sich die verwendeten Klassen nicht mehr selbst um Ablauf und Abhängigkeiten kümmern, sondern diese werden an eine externe Komponente ausgelagert. Die Klasse gibt vermeintlich die Kontrolle ab und lässt sich von außen steuern. Konkret bedeutet es, dass die Klassen nur die Abhängigkeiten zu den Interfaces deklarieren müssen und die konkrete Implementierung zur Laufzeit eingefügt (injected) wird. 

Die genauere Zusammensetzung einer Anwendung wird deklarativ definiert, sodass verschiedene Konfigurationen existieren können.

Die Einhaltung des \textit{Dependency Inversion} Prinzips zusammen mit der Anwendung des \di\ Patterns ermöglicht den Entwicklern, den Arbeitsaufwand für die Entwicklung großer Anwendungen stark zu reduzieren.
Es wird eine \textbf{lose Kopplung} der Anwendungskomponenten erreicht, die dem Entwickler die Konzentration auf die Entwicklung einzelner Komponenten unabhängig voneinander ermöglicht. Die Unabhängigkeit der Programmteile erleichtert dem Entwickler nicht nur die Anwendungskomponenten unabhängig voneinander zu entwicklen, sondern auch diese leichter zu testen. 

\subsubsection{Dependency Injection und Mock-Objekte}
%\subsubsection{\colorbox{green}{Dependency Injection und Mock-Objekte}}\label{di}

Enge Kopplung von Abhängigkeiten erschwert nicht nur die Erweiterung oder Änderung von Codebasis, sondern auch die Testbarkeit. Beispielsweise sollten die Komponenten unabhängig von den anderen Komponenten mit \textit{UnitTests} getestet werden. Dafür werden die Abhängigkeiten zu anderen Komponenten simuliert. Falls die zu testende Methode die Daten aus der Datenbank für die Berechnung benötigt, kann die Datenbankverbindung simuliert und die Testdaten zurückgegeben werden. Solche Klassen, die die Abhängigkeiten simulieren, nennt man \textbf{Mock-Klassen}.

Die lose Kopplung des \textit{DI} Patterns ermöglicht die Verwendung von Mock-Objekten. Die entsprechenden Abhängigkeiten werden zur Laufzeit von Tests von dem entsprechenden Framework injiziert, sodass seitens des Entwicklers keine weiteren Schritte notwendig sind.

\subsubsection{MVC-Pattern}\label{mvc}
%\subsubsection{\colorbox{green}{MVC-Pattern}}\label{mvc}

\textbf{MVC}\cite{mvc} ist ein Prinzip der modernen Programmierung und ist nach wie vor das wichtigste und verbreitetste Muster für die Architektur von GUI-Anwendungen. Solche Architektur kommt fast bei allen GUI-Frameworks zum Einsatz.

Das Ziel des \textbf{MVC}-Musters ist, die Geschäftslogik einer Anwendung von der Benutzerschnittstelle abzutrennen, so dass ein Entwickler einen Bereich bequem verändern kann und der Rest der Anwendung dadurch nicht beeinflusst wird. Es soll einen flexiblen Programmierentwurf geben, der eine spätere Änderung oder Erweiterung erleichtert und eine Wiederverwendbarkeit und Austauschbarkeit einzelner Komponenten ermöglicht.

\paragraph{Workflow}
%\paragraph{\colorbox{green}{Workflow}}

Der Workflow-Prozess \textbf{(Abb. \ref{img:mvc})} stellt eine vollständige Beschreibung aller Aktivitäten, der den Einsatz des \textbf{MVC}-Patterns voraussetzt. Die Abbildung \ref{img:mvc} stellt einen groben Workflow des \textbf{MVC}-Patterns anhand einer Beispielinteraktion und ihres Ergebnisses dar.
\begin{figure}[H]
\centering
\includegraphics[trim = 0mm 60mm 0mm 20mm, clip, width=1.0\textwidth]{resources/mvc}
\caption[Workflow zum MVC-Konzept]{Workflow zum MVC-Konzept}
\label{img:mvc}
\end{figure}

\textbf{Beschreibung des Workflow-Prozesses:}
\begin{enumerate}
\item \textbf{Der Benutzer interagiert mit der View}

Der Benutzer führt eine Aktion an der View aus. Dadurch teilt die View dem Controller mit, was zu tun ist. Erst dann ist die Aufgabe des Controllers, entsprechende Steuerungsmaßnahmen zu ergreifen.

\item  \textbf{Der Controller fordert das Model auf, seinen Zustand zu ändern}

Nach der Ausführung einer Aktion an der View durch den Benutzer, nimmt der Controller diese Aktion an und interpretiert sie. Bei der Interpretation stellt der Controller fest, was gemacht werden muss und wie das Model aufgrund dieser Aktion beeinflusst werden kann.

\item  \textbf{Der Controller kann auch die View auffordern, ihren Zustand zu ändern}

Der Controller kann bei der Ausführung einer Aktion auch die View auffordern, sich zu ändern. Zum Beispiel, beim Klick auf einen Button durch den Benutzer kann die gerade eingeblendete View ausgeblendet und eine andere View eingeblendet werden.

\item  \textbf{Das Model informiert die View über seine Zustandsänderung}

Dem Model selbst sind Views und Controller nicht bekannt bzw. diese sind an dem Model nicht festprogrammiert. Aber das Model kann diejenigen, die sich beim Model registriert haben, über seine Zustandsänderungen informieren.

\item  \textbf{Die View erfragt den Zustand des Models}

Das Model stellt weitere Methoden zur Verfügung, über die der aktuelle Zustand des Models erfragt werden kann. Jede View kann sich somit durch den Aufruf dieser Methoden über den Zustand des Models informieren.

\end{enumerate}
Um die Benachrichtigung über Modelsänderungen an Views oder auch an Controller zu realisieren, nutzt MVC das sogenannte Beobachter Muster.

\paragraph{Beobachter Muster}\label{observer}
%\paragraph{\colorbox{green}{Beobachter Muster}}\label{observer}

Beobachter Muster (engl. Observer-Pattern) ist eines der am meisten genutzten und bekanntesten Patterns. In diesem Muster teilt die Komponente Model allen Interessenten proaktiv mit, dass ihr Zustand geändert wurde.

Würde man ohne das \textbf{Observer}-Pattern eine solche `Beobachtung` implementieren, so müssten die Interessenten die Komponente Model regelmäßig abfragen, ob ihr Zustand geändert wurde.

Beim \textbf{Observer}-Pattern gibt es eine Komponente (Observable), deren Zustand sich ändern kann und andere Komponenten (Observers), die über Zustandsänderung informiert werden sollten. Das \textbf{Observer}-Pattern sieht vor, dass sich die Observers beim Observable registrieren und bei einer Zustandsänderung alle registrierte Objekte informiert.

\begin{figure}[H]
\centering
\includegraphics[trim = 0mm 0mm 0mm 0mm, clip, width=0.8\textwidth]{resources/observer}
\caption[Observer Pattern]{Observer Pattern}
\label{img:observer}
\end{figure}

\textbf{Beschreibung des \textbf{Observer}-Pattern Prinzips:}

Die Abbildung \ref{img:observer} zeigt, wie \textbf{Observer}-Pattern im \textbf{MVC} verwendet wird. Wenn eine View bei einer Zustandsänderung des Models informiert werden möchte, registriert sie sich beim Model. Die View wird somit in die Liste hinzugefügt, in der sich bereits andere Observers befinden können. Im Fall einer Zustandsänderung läuft das Model die Liste durch und informiert somit alle, die sich als Beobachter eingetragen haben.

\section{Relevante Technologien}
%\section{\colorbox{yellow}{Relevante Technologien}}

Dieser Abschnitt widmet sich den aktuellen Technologien, die für den Prototyp relevant sind.

\subsection{NoSQL-Datenbanken}
%\subsection{\colorbox{yellow}{NoSQL-Datenbanken}}

Im Vergleich zu den relationalen Datenbanken, die sich als eine strukturierte Sammlung von Tabellen (den Relationen) vorstellen, in welchen Datensätze abgespeichert sind, eignen sich \textit{NoSQL}-Datenbanken zur unstrukturierter Daten, die einen nicht-relationalen Ansatz verfolgen. 

Der Begriff NoSQL steht nicht für 'kein SQL', sondern für 'nicht nur SQL' (Not only SQL). Das Ziel von NoSQL ist, relationale Datenbanken sinnvoll zu ergänzen, wo sie Defizite aufzeigen. Entstanden ist dieses Konzept in erster Linie als Antwort zur Unflexibilität, sowie zur relativ schwierigen Skalierbarkeit von klassischen Datenbanksystemen, bei denen die Daten nach einem stark strukturierten Modell gespeichert werden müssen. \cite{mySQL} Dokumentdatenbanken gruppieren die Daten in einem strukturierten Dokument, typischerweise in einer \textit{JSON}-Datenstruktur \cite{json}. \mongo\ ist eine von vielen NoSQL-Datenbanken, die auch diesen Ansatz verfolgt und bietet darauf aufbauend eine reichhaltige Abfragesprache und \textit{Indexe} auf einzelne Datenfelder. Die Möglichkeiten der \textit{Replikation} und des \textit{Shardings} zur stufenlosen und unkomplizierten Skalierung der Daten und Zugriffe macht \mongo\ auch für stark frequentierte Websites äußerst interessant.(\cite{Hollosi.2012}, Kapitel 14, Seite 435)

Beispiele für NoSQL-Datenbanken:
\begin{multicols}{2}
\begin{itemize}
\item CouchDB
\item MongoDB
\item Redis
\item Google BigTable
\item Amazon Dynamo
\item Apache Cassandra
\item Hbase (ApacheHadoop)
\item Twitter Gizzard
\item weitere…
\end{itemize}
\end{multicols}

Jede NoSQL-Datenbank verfolgt seine eigenen Ziele und ist kategorisiert. Die möglichen Kategorien werden demnächst näher erläutert.

\begin{itemize}
\item Eine Key-Value-Datenbank \textit{(Key-Value Store)} ist eine Datenbank, in der die Daten in Form von Schlüssel-Werte-Paaren abgespeichert werden. Der Schlüssel verweist dabei auf einen eindeutigen (meist in Binär- oder Zeichenketten-Format vorliegenden) Wert \cite{nosql}. Value kann oft beliebiger Datentyp wie Arrays, Dokumente, Objekte, Bytes etc. sein.

\item In einer spaltenorientierten Datenbank \textit{(Column Store)}, wie der Name vermuten lässt, werden die Datensätze spalten- statt zeilenweise abgespeichert. Durch die spaltenorientierte Abspeicherung der Daten wird der Lesezugriff stark beschleunigt, da keine unnötigen Informationen mehr gelesen werden, stattdessen nur diejenigen, die wirklich benötigt wurden. Dadurch wird der Schreibprozess aber erschwert, falls die schreibenden Daten aus mehreren Spalten bestehen werden, auf die entsprechend zugegriffen werden muss. Der Schreibprozess wird sich in diesem Fall etwas verlangsamen.

\item Eine Graphen-Datenbank \textit{(Graph database)} ist die weitere Kategorie aus der NoSQL Gruppe, in der die Daten anhand eines Graphen dargestellt und abgespeichert werden.

Die Graphen bestehen grundsätzlich aus Knoten \textit{(Node)} und Kanten \textit{(Edge)}. Dabei stellen die Kanten die Verbindungen zwischen den einzelnen Knoten dar.

\item Eine Datenbank, in der die Daten in Form von Dokumenten abgespeichert werden, ist als eine dokumentenorientierte Datenbank \textit{(Document Store)} zu definieren. In diesem Zusammenhang ist ein Dokument als eine Zusammenstellung bestimmter Daten zu verstehen, das mit einem eindeutigen Identifikator angesprochen werden kann. Da die Daten in der dokumentenorientierten Datenbank nicht in Form von Tabellen, sondern in Form von Dokumenten abgespeichert werden, ergibt sich daraus keinen Strukturzwang.

Möchte man ein bestimmtes Dokument erweitern, so kann man es einfach tun, da eine dokumentenorientierte Datenbank strukturfrei ist. Weitere Datenformate sind beispielsweise YAML \cite{yaml} (angelehnt an XML) oder XML \cite{xml} selbst. 
\end{itemize}

%Bei dem Auswahl einer Datenbank für Foto-Verwaltungs-Service fiel die Entscheidung auf eine der NoSQL-Datenbank \mongo. Laut DB-Ranking\footnote{DB-Ranking: \url{http://db-engines.com/de/ranking}, zugegriffen am 13. März 2017} ist die \mongo\ einer der populärsten Datenbanken aus der NoSQL-Gruppe und passt ideal für Webprojekte mit \textit{Big Data}.

\subsubsection{MongoDB}\label{mongo}
%\subsubsection{\colorbox{green}{MongoDB}}\label{mongo}

\mongo\ ist eine  schemalose, dokumentenorientierte Open-Source-Datenbank. Der Name stammt von dem englischen Begriff \textit{hu}MONGO\textit{us}, ins Deutsche als \textit{gigantisch} oder \textit{riesig} übersetzen lässt.


%\rowcolors{1}{white}{lightgray}
%\newcommand*{\head}[1]{\textbf{#1}}%
%
%\rowcolors{2}{gray!25}{white}
%\begin{table}[h]
%\centering
%\begin{tabular}{cc}
%\toprule 
%    \rowcolor{gray!50}
%	Relational & \mongo\ \\
%	\midrule
%	Database &  Database\\
%	Table & Collection\\
%	Row &  Document\\
%	Column &  Field\\
%	Index & Index\\
%	Join &  Embedding and Linking\\
%	Primary key & \textit{\_id}-Field (default)\\
%	\bottomrule
%\end{tabular}
%\caption[Konzepte im Vergleich]{Konzepte im Vergleich}
%\label{table:concepts}
%\end{table}

\mongo\ präsentiert sich als eine quelloffene, dokumentenorientierte NoSQL-Datenbank mit den folgenden Konzepten wie \textit{Ausfallsicherheit} und \textit{horizontale Skalierung} (\textbf{Kap. \ref{cap}}).
%Die Unterschiede zu den Konzepten der relationalen und nicht-relationalen Datenbanken, konkret von \mongo\ stellt die Tabelle \ref{table:concepts} dar.

\paragraph{Datensätze in Form von Dokumenten}
%\subsection{Datensätze in Form von Dokumenten}
%Die Datensätze werden in  der NoSQL-Datenbank \mongo\ in Dokumente gespeichert. \mongo\ verwendet für die Dokumentenspeicherung und den Datenaustausch das sogenannte \textit{BSON}\footnote{BSON: \url{http://www.bjson.org}}-Format, das eine binäre Darstellung von \textit{JSON}-ähnlichen Dokumenten bietet. Nachfolgend sind alle für \textit{BSON} definierten Datentypen aufgelistet:
%\begin{multicols}{3}
%\begin{itemize}
%\item Double
%\item String
%\item Object
%\item Array
%\item Binary Data
%\item Undefined
%\item Object Id
%\item Boolean
%\item Date
%\item Null
%\item Regular Expression
%\item JavaScript
%\item Symbol
%\item JavaScript(with scope)
%\item 32-Bit Integer
%\item Timestamp
%\item 64-Bit Integer
%\item Min Key
%\item Max Key
%\end{itemize}
%\end{multicols}
%Der Grund für die große Anzahl an Datentypen ist ein wesentliches Ziel der Entwickler von \textbf{BSON}: \textit{Effizienz.}

Die Daten speichert \mongo\ in Form von Dokumenten im \textbf{BJSON}-Format \cite{bjson}. Die Dokumente selbst werden in sogenannten Kollektionen \textit{(Collections)} gespeichert, die grob mit den Tabellen einer relationalen Datenbank vergleichbar sind. Ein Zugriff auf Daten mehrerer Kollektionen \textit{(Collections)}, wie es aus dem \textit{Joins}-Konzept relationaler Datenbank bekannt ist, ist nicht möglich. Die \textit{CRUD}-Operationen sind auf Ebene der \textit{Collection} durchzuführen. Jedes Dokument ist an keine vordefinierte Struktur gebunden und kann eine beliebige Anzahl an Feldern besitzen. Die Dokumente aus einer \textit{Collection} sind komplett unabhängig voneinander. 

Die Speicherung von Daten in Form von Dokumenten bietet den Vorteil, das sowohl strukturierte, als auch semi-strukturierte und polymorphe Daten gespeichert werden können. Dokumente, die jedoch das gleiche oder ein ähnliches Format haben, sollten zu einer Kollektion \textit{(Collection)} zusammengefasst werden \cite{documentInMongo}.

%\paragraph{\colorbox{yellow}{Server/Client starten}}
%%\paragraph{Server/Client starten}
%Zum Starten des Server-Prozesses muss im Terminal der folgende Befehl ausgeführt werden:
%\begin{listingsboxShell}[label={lst:serverStart}]{myshell}{Server-Prozess starten}
%vlfa:~ vlfa$ mongod
%\end{listingsboxShell}
%Mit dem Befehl
%\begin{listingsboxShell}[label={lst:mongoClient}]{myshell}{Client-Prozess starten}
%vlfa:~ vlfa$ mongo
%\end{listingsboxShell}
%wird ein Client-Prozess gestartet, falls die \textit{mongod-}Instanz aktiv ist.
%Nachdem das Client-Prozess gestartet ist, kann der Client an der Datenbank \textit{CRUD-}Operationen ausführen.
%
%Ohne irgendeine Konfiguration vornehmen zu müssen, verwendet \mongo-Server von Anfang an als \textit{Default} den TCP-IP-Port 27017 für eingehende Verbindungen.
%
%\mongo\ unterstützt auch eine HTML-basierte Administrationsoberfläche. Falls sie benötigt wird, ist es möglich, im Terminal mit dem folgenden Befehl die HTML-basierte Administrationsoberfläche zu starten:
%\begin{listingsboxShell}[label={lst:html}]{myshell}{HTML-basierte Administrationsoberfläche starten}
%vlfa:~ vlfa$ mongod --httpinterface --rest
%\end{listingsboxShell}
%und dementsprechend sie im beliebigen Browser der folgenden URL aufzurufen:
%\begin{listingsboxShell}[label={lst:browser}]{myshell}{HTML-basierte Administrationsoberfläche aufrufen}
%http://localhost:28017/
%\end{listingsboxShell}
%Auf der Seite sind alle relevante Informationen zu Replikaktionsgruppen, Skalierung, verbundene Clients etc. zu finden.
%
%\paragraph{\colorbox{yellow}{CRUD = IFUR-Operationen}\label{ifur}}
\paragraph{CRUD = IFUR-Operationen}\label{ifur}
Die \textit{\textbf{CRUD}}-Operationen aus SQL heißen in \mongo\ \textit{\textbf{I}nsert}, \textit{\textbf{Fi}nd}, \textit{\textbf{U}pdate} und \textit{\textbf{R}emove}. Bei \mongo\ wird eine Datenbank bzw. eine Collection erst zur Laufzeit und beim ersten Einfügen des ersten Dokuments von \mongo\ selbst erzeugt. Die gesonderte Erstellung einer Datenbank oder einer Collection kann somit erspart werden.
\begin{itemize}
\item Für die Speicherung von neuen Dokumenten in der Datenbank bietet \mongo\ drei Funktionen an, welche als Parameter ein einzelnes oder eine Reihe von Dokumenten in einem Array annehmen. %Die \textit{Collection} muss vor dem Einfügen von neuen Dokumenten nicht explizit angelegt werden. Falls sie nicht existiert, wird sie zunächst erstellt und die übergebenen Dokumente eingefügt.
\begin{listingsboxShell}[label={lst:insert}]{myshell}{Dokument(e) speichern}
> db.<collection>.insert(<...>)
> db.<collection>.insertMany(<...>)
> db.<collection>.insertOne(<...>)
\end{listingsboxShell}
\mongo\ generiert für jedes neues Dokument eine ID mit dem Feldnamen \textit{\_id}, falls keine konkrete Dokument\_ID angegeben ist.

\item Zum Durchsuchen nach Dokumenten mit bestimmten Eigenschaften bietet \mongo\ drei weitere Funktionen an. Das Ergebnis beim Aufruf einer der folgenden Funktionen ist ein Cursor, der auf alle passenden Dokumente zeigt.
\begin{listingsboxShell}[label={lst:find}]{myshell}{Dokument(e) finden}
> db.<collection>.find(<...>)
> db.<collection>.findOne(<...>)
> db.<collection>.findOneAndDelete(<...>)
\end{listingsboxShell}

\item Die drei nächsten Funktionen ermöglichen, anhand des Inhalts bestimmte Dokumente zu filtern und in diesen Änderungen durchzuführen. Die Änderungen umfassen das Hinzufügen, Entfernen oder Umbenennen von Feldern.
\begin{listingsboxShell}[label={lst:update}]{myshell}{Dokument(e) aktualisieren}
> db.<collection>.update(<...>)
> db.<collection>.updateMany(<...>)
> db.<collection>.updateOne(<...>)
\end{listingsboxShell}

\item Das Löschen von ganzen Dokumenten erfolgt in \mongo\ anhand der folgenden Funktion, indem beim Aufruf entsprechende Informationen für die Dokumente angegeben werden.
\begin{listingsboxShell}[label={lst:remove}]{myshell}{Dokument(e) löschen}
> db.<collection>.remove(<...>)
\end{listingsboxShell}
\end{itemize}

%\paragraph{\colorbox{yellow}{Indizes}}
\paragraph{Indizes}
Um die Laufzeit von Datenbankabfragen zu optimieren bzw. zu beschleunigen, können Indexe verwendet werden. Indexe in MongoDB werden als \textit{B-Tree}-Datenstrukturen \cite{b-tree} verwaltet.

Neben dem obligatorischen Primär-Index auf dem Feld \textit{\_id} ist es möglich, beliebige Sekundärindexe anzulegen. Insgesamt erlaubt \mongo\, pro Collection auf einzelnen Feldern oder einer Gruppe von Feldern bis zu 64 Indexe zu definieren.

Auf der Kommandozeile ist es möglich, das Administrationswerkzeug \textit{Mongo Shell} zu verwenden, um mit einer Collection aus einer Datenbank verbinden zu können. Indexe anzulegen, ermöglicht \mongo\ mit dem folgenden Befehl: 
\begin{listingsboxShell}[label={lst:createIndex}]{myshell}{Index auf ein Feld anlegen}
> db.<collection>.createIndex( {<feld>: 1} )
\end{listingsboxShell}

%\paragraph{\colorbox{yellow}{Aggregation}}\label{aggr}
\paragraph{Aggregation}\label{aggr}
\mongo\ bietet eine Menge von Aggregationsoperationen an, die die Datensätze wunschmäßig verarbeiten und die berechneten Ergebnisse zurückliefern. Die Aggregationsoperationen gruppieren Werte aus mehreren Dokumenten zusammen. Des Weiteren ist es möglich, eine Vielzahl von Operationen auf den gruppierten Daten auszuführen, um ein einziges Ergebnis zurückzuliefern. \mongo\ bietet drei Möglichkeiten, Datenaggregation durchzuführen. Diese sind 
\begin{itemize}
\item Aggregation Framework
\item Map/Reduce und
\item Single purpose aggregation.\cite{aggr}
\end{itemize}

\paragraph{Aggregation Framework}\label{aggrFr}
%\paragraph{\colorbox{yellow}{Aggregation Framework}}\label{aggrFr}

%Aggregation Framework ist ein Konzept, das \mongo\ für die Datenaggregation modelliert hat, um Entwicklern die Arbeit bei den komplexen Abfragen ohne fundierte JavaScript-Kenntnisse erleichtern zu können. 
Analog zu \textit{GROUP BY} in SQL hat \mongo\ sein eigenes Konzept entwickelt, das im eigenen Aggregation Framework modelliert ist. Die einzelnen Aggregationsoperationen mit entsprechender Beschreibung sind aus der Tabelle \ref{table:aggrOperators} zu entnehmen. %Die Datenaggregation durch das Aggregation Framework ist natürlich nicht nur auf \textit{Shell-}Ebene, sondern auch in vielen gängigen Programmiersprachen, wie zum Beispiel Java, C++, C\#, PHP, Python etc. durch bereitgestellte \mongo's Treiber\footnote{MongoDB Drivers: \url{https://docs.mongodb.com/ecosystem/drivers/}, zugegriffen am 18. Januar 2017} möglich.

\rowcolors{1}{white}{lightgray}
\newcommand*{\head}[1]{\textbf{#1}}%

\rowcolors{2}{gray!25}{white}

\begin{table}[H]
\centering
\begin{tabular}{lp{2.3cm}p{10.3cm}}
\toprule 
    \rowcolor{gray!50}
	\mongo & SQL & Beschreibung\\
	\midrule
	\$match & WHERE, HAVING & Der \textit{\$match-}Operator funktioniert nach dem gleichen Prinzip wie \textit{db.<collection>.find({})}.\\
	\$group & GROUP BY & Der \textit{\$group-}Operator gruppiert berechnete Ergebnisse nach bestimmten Feldern.\\
	\$skip & - & Der \textit{\$skip-}Operator ermöglicht, eine bestimmte Anzahl an Dokumenten zu überspringen.\\
	\$limit & - & Der \textit{\$limit-}Operator formuliert eine konkrete Anzahl an zurücklieferenden Dokumenten.\\
	\$sort & ORDER BY & Der \textit{\$sort-}Operator sortiert Dokumente.\\
	\$project  & SELECT & Der \textit{\$project-}Operator ermöglicht, die Form der berechnenden Ergebnisse zu manipulieren, bzw. das zurücklieferende Ergebnis wunschmäßig zu formen-\\
	\$unwind  & - & Der \textit{\$unwind-}Operator dekonstruiert ein Array-Feld aus einem Dokument, falls so ein Array-Feld existiert-\\
	\bottomrule
\end{tabular}
\caption[Aggregationsoperationen]{Aggregationsoperationen}
\label{table:aggrOperators}
\end{table}
%\subsection{Map/Reduce}\label{map}
%\mongo\ bietet auch eine eigene Implementierung des Map/Reduce-Algorithmus an.

%\paragraph{\colorbox{yellow}{Replikation (Replication)}}\label{replication}
\paragraph{Replikation (Replication)}\label{replication}
Manchmal kann es dazu kommen, dass ein Server ausfällt und die Schreib- und Lesezugriffe dadurch auf eine kurze Zeit nicht möglich sind. Um Schreib- und Lesezugriffe auch im Fall eines Serverausfalles ständig ermöglichen zu können, hat \mongo\ einen Replikationsmechanismus, basierend auf das CAP-Theorem, entwickelt. Der Replikationsmechanismus dient zur Replikation bzw. zum Spiegeln der Daten auf mehreren Servern und funktioniert nach einem \textit{Master-n-Slaves-Prinzip.}
\begin{figure}[H]
   \begin{subfigure}[t]{0.49\textwidth}\vspace{0pt}
   \centering
      \includegraphics[trim = 28mm 139mm 28mm 29mm, clip, width=0.9\textwidth]{resources/replicaSet/createReplicaSet2}
      \caption[Initialer Zustand des Replica Sets]{Initialer Zustand des Replica Sets}
      % \caption[Ein Beispiel für eine Replikationsgruppe]{Ein Beispiel für eine Replikationsgruppe}
      \label{img:createReplicaSet}
   \end{subfigure}\hfill%
   \begin{subfigure}[t]{0.49\textwidth}\vspace{0pt}
   \centering
      \includegraphics[trim = 28mm 139mm 28mm 29mm, clip, width=0.9\textwidth]{resources/replicaSet/selectNewPrimary}
     \caption[Ausfall des \textbf{Primary}-Knotens]{Ausfall des \textbf{Primary}-Knotens}
      \label{img:selectNewPrimary}
   \end{subfigure}\\[5pt]%
   \centering
   \begin{subfigure}[t]{0.49\textwidth}\vspace{0pt}
   \centering
        \includegraphics[trim = 28mm 139mm 28mm 29mm, clip, width=0.9\textwidth]{resources/replicaSet/newReplicaSet}
      \caption[Neuer \textbf{Primary} wurde gewählt]{Neuer \textbf{Primary} wurde gewählt}
      \label{img:newReplicaSet}
   \end{subfigure}
   \caption{Szenario für eine Replikationsgruppe mit drei Servern in einer \textit{Shard}}
   \label{img:replicaSetSzenario}
\end{figure}
Ein \textit{Master}, auch ein \textit{Primary} genannt, besitzt Schreib- und Leserechte. Dieser repliziert die Daten auf \textit{n-Slaves}, die auch als \textit{Secondaries} bezeichnet werden. Ein \textit{Primary} mit \textit{n-Secondaries} bilden gemeinsam eine \textit{Shard}. Eine \textit{Shard} kann aus mind. einem Server bestehen. Falls eine \textit{Shard} aus mehreren Servern besteht, so kann \mongo\ die Server in Replikationsgruppe \textit{(Replica set)} anordnen, damit bei Ausfall eines Servers die Verfügbarkeit der Datenbank trotzdem gewährleistet ist. Mit Replikationsgruppen will \mongo\ die Ausfallsicherheit sicherstellen. Die Abbildung \ref{img:replicaSetSzenario} veranschaulicht ein Szenario für eine Replikationsgruppe mit drei Knoten. Jeder Knoten aus der Gruppe ist als einen eigenen Server vorzustellen. %Das \textit{Master-n-Slaves-Prinzip} besagt, dass in einer Replikationsgruppe nur ein Master und n-Slaves existieren können, um eine strenge Konsistenz gewährleisten zu können. 
\begin{figure}[H]
   \begin{subfigure}[t]{0.49\textwidth}\vspace{0pt}
   \centering
    	\includegraphics[trim = 0mm 90mm 0mm 20mm, clip, width=1.0\textwidth]{resources/replicaSet/replicaSetStrongConsistency}
	\caption[Lesezugriffe nur über Primary möglich]{Lesezugriffe nur über \textbf{Primary} möglich}
	\label{img:slaveNotOk}
   \end{subfigure}\hfill%
   \begin{subfigure}[t]{0.49\textwidth}\vspace{0pt}
   \centering
	\includegraphics[trim = 0mm 90mm 0mm 20mm, clip, width=1.0\textwidth]{resources/replicaSet/eventualConsistency}
	\caption[Lesezugriffe auch über Secondaries freigeschaltet]{Lesezugriffe auch über \textbf{Secondaries} freigeschaltet}
	\label{img:slaveOk}
   \end{subfigure}\\[5pt]%
   \caption{Freischaltung der Lesezugriffe}
   \label{img:secondariesLowToRead}
\end{figure}
Im Gegenteil zu dem Primary sind bei Secondaries die Schreib- und Leserechte von Anfang an nicht möglich. Falls der Kontext der Anwendung verlangt, können nur die Leserechte auch bei Secondaries entsprechend freigeschaltet werden. Bei der Freischaltung der Leserrechte durch Secondaries muss jedoch in Kauf genommen werden, dass das Lesen durch Secondaries den konsistenten Zustand an Daten jedoch nicht garantiert. Der Grund dafür ist, dass die Schreiboperationen nur über den Master erfolgen und die Replikation der Daten etwas Zeit nimmt.

%\paragraph{\colorbox{yellow}{Horizontale Skalierung (Sharding)}}\label{sharding}
\paragraph{Horizontale Skalierung (Sharding)}\label{sharding}

Um eine kostengünstige Lösung für eine Steigerung der Leistung von Systemen zu ermöglichen, ermöglicht das Datenbanksystem von \mongo\  eine horizontale Skalierung. Die horizontale Verteilung der Daten erfolgt bei \mongo\ auf Ebene der \textit{Collections} nach \textit{Sharding-Keys}. Die \textit{Sharding-Keys} dienen dazu, um später Zugriffe auf einzelne Dokumente zu ermöglichen, die auf verschiedenen Servern abgelegt sind.
\begin{figure}[H]
\centering
\includegraphics[trim = 0mm 35mm 0mm 30mm, clip, width=1.0\textwidth]{resources/replicaSet/sharding}
\caption[Ein Beispiel für Verteilung einer \textit{Collection} auf mehreren \textit{Shards}]{Ein Beispiel für Verteilung einer \textit{Collection} auf mehreren \textit{Shards}}
\label{img:sharding}
\end{figure}
Die Aufteilung der \textit{Collections} erfolgt in Blocks, auch als \textit{Chunks} genannt. Ein \textit{Chunk} ist ein Teil einer bestimmten \textit{Collection}. Gespeichert werden \textit{Chunks} auf Servern, die in diesem Zusammenhang als \textit{Shards} bezeichnet werden.

Um die Aufteilung der \textit{Collections} in \textit{Chunks} auf \textit{Shards} realisieren zu können, verwendet \mongo\ folgende Komponenten:
\begin{itemize}
\item \textit{shards:} Die \textit{Shards} enthalten letztendlich die Daten. In einer \textit{Shard} ist es möglich, Replikationsgruppen zu verwenden.
\item \textit{mongos:} Der \textit{mongos} gilt als ein \textit{RoutingService}, der die Anfragen der Anwendungsschicht entgegennimmt und diese an eine entsprechende \textit{Shard} weiterleitet, die die nötigen Daten enthält.
\item \textit{config servers:} Die Konfigurationsserver speichern die Metadaten für einen Sharded-Cluster. Im Fall einer Schreiboperation entscheiden die Konfigurationsserver, in welchen Chunk auf welchem Shard das entsprechende Dokument eingefügt wird. Bei der Leseoperation geben die Konfigurationsserver den Auskunft darüber, welcher Shard die gewünschten Daten enthält. Bei den Konfigurationsservern handeln es um eine \textit{mongod-}Instanzen.
\end{itemize}
Die Abbildung \ref{img:shardedCluster} veranschaulicht die Interaktion von den gerade genannten Komponenten innerhalb eines Sharded-Cluster:
%\colorbox{red}{graphische Darstellung}
\begin{figure}[H]
\centering
\includegraphics[trim = 0mm 139mm 0mm 22mm, clip, width=0.7\textwidth]{resources/replicaSet/shardedCluster}
\caption[Horizontale Skalierung \textit{(Sharding)}]{Horizontale Skalierung \textit{(Sharding)}}
\label{img:shardedCluster}
\end{figure}

Das Ziel des Ganzen ist die horizontale Skalierbarkeit an Datenmengen, um die Performance des Datenbanksystems zu steigern.

%\paragraph{\colorbox{yellow}{Fragmentierung nach \textit{Shard-Keys}}}\label{sharding-keys}
\paragraph{Fragmentierung nach \textit{Shard-Keys}}\label{sharding-keys}
Die Fragmentierung der Daten erfolgt auf Ebene der \textit{Collections} nach \textit{Shard-Keys}. In jeder \textit{Collection}  muss ein Schlüssel als sogenannter \textit{Sharding-Key} definiert sein, der entsprechend in jedem Dokument derselben \textit{Collection} existiert.  \textit{Sharding-Key} kann entweder aus einem einzigen indexierten Feld oder einem zusammengesetzten Index bestehen. Die Dokumente werden dann nach \textit{Shard-Key} alphabetisch oder nummerisch sortiert und anschließend in \textit{n-}Blocks gleicher Größe eingeteilt. \mongo\ garantiert die gleichmäßige Verteilung der Blocks an \textit{Shards}.
\begin{figure}[H]
\centering
%trim = links, unten, rechts, oben
 \includegraphics[trim = 25mm 240mm 40mm 20mm, clip, width=0.9\textwidth]{resources/replicaSet/sharding-keys}
\caption[Anordnung der Dokumente in Blocks (=\textit{Chunks}) unter Verwendung des \textit{Shard-Keys}. Mehrere Blocks bilden dementsprechend eine \textit{Shard}.]{Anordnung der Dokumente in Blocks (=\textit{Chunks}) unter Verwendung des \textit{Shard-Keys}. Mehrere Blocks bilden dementsprechend eine \textit{Shard}.}
\label{img:shardKeys}
\end{figure}

Bei der \textit{Shard-Keys} Konfiguration müssen folgende \textit{Constraints}  \cite{sharding} berücksichtigt werden:
\begin{itemize}
\item \textit{Shard-Keys} sind unabänderlich
\item \textit{Shard-Keys} verfügen über eine hohe Kardinalität
\item \textit{Shard-Keys} sind eindeutig
\item \textit{Shard-Keys} existiert dann in jedem Dokument
\item \textit{Shard-Keys} ist bis zum 512 bytes limitiert
\item \textit{Shard-Keys} ist es nicht möglich, als Multi-Key zu bilden
\end{itemize}

%\paragraph{\colorbox{yellow}{GridFS}}
\paragraph{GridFS}
Für die Daten, die eine Größe in Höhe von 16MB überschreiten, stellt \mongo\ ein Dateisystem namens \textbf{GridFS} zur Verfügung. Abgelegt werden solche Daten in zwei spezielle \textit{Collections}:

\begin{itemize}

\item \textit{fs.files} - die \textit{fs.files-Collection} enthält die Metainformationen zu den einzelnen Dokumenten. Listing \ref{lst:fsFileDocument} veranschaulicht ein Beispiel dazu.
\item \textit{fs.chunks} - in \textit{fs.chunks-Collection} werden die eigentlichen Daten gespeichert.

\end{itemize}

\begin{listingsboxJava}[label={lst:fsFileDocument}]{myjson}{Beispiel für ein Dokument in \textit{fs.files-Collection}}
{
	"_id" : ObjectId("58f5f0056ce5d24528e152c3"),
	"filename" : "Bicycle.jpeg",
	"aliases" : null,
	"chunkSize" : NumberLong(261120),
	"uploadDate" : ISODate("2017-04-18T10:52:53.974Z"),
	"length" : NumberLong(68090),
	"contentType" : "image/jpeg",
	"md5" : "85a866edfca999c0163e7bbc7cd5269b"
}
\end{listingsboxJava}

%\paragraph{\colorbox{yellow}{Treiber für MongoDB}}
\paragraph{Treiber für MongoDB}
Alle mögliche Operationen, die \mongo\ zur Verfügung stellt, sind nicht nur auf \textit{Shell-}Ebene, sondern auch in vielen gängigen Programmiersprachen, wie zum Beispiel Java, C++, C\#, PHP, Python etc. durch bereitgestellte \mongo's Treiber \cite{mongoTreiber} möglich.

\subsubsection{Apache Cassandra}
%\subsubsection{\colorbox{yellow}{Apache Cassandra}}

In diesem Kapitel wird ein weiterer wichtiger Vertreter der NoSQL-Datenbanken vorgestellt, nämlich \cass.

\cass\ war ursprünglich eine proprietäre Datenbank von Facebook und wurde 2008 als Open-Source-Datenbank veröffentlicht. Konzipiert ist \cass\ als skalierbares, ausfallsicheres System für den Umgang mit großen Datenmengen auf verteilten Systemen (Clustern) und im Gegensatz zu \mongo\ (C++) in Java geschrieben.

%Zunächst werden die Konzepte von \cass\ allgemein diskutiert und dann die Unterschiede zu der schon besprochenen NoSQL-Datenbank \mongo\ gezeigt.

%Die spaltenorientierten Datenbanken können Datensätze mit beliebiger Spaltenanzahl aufnehmen. Je Datensatz kann über bis zu 2 Milliarden Spalten verfügen.
Im Vergleich zu der \mongo-Datenbank, die in Replikation nach dem Master-Slave-Prinzip funktioniert, verfolgt \cass\ komplett anderes Prinzip. %Dieses Prinzip wird in der Architektur der \cass\ erläutert.

\paragraph{Architektur}
%\paragraph{\colorbox{yellow}{Architektur}}

\begin{itemize}
\item \cass\ ist nach peer-to-peer\footnote{Peer-to-Peer-Netze (P2P) sind Netze, bei denen alle Knoten im Netz dezentral sind.} verteiltes System aufgebaut. Ein peer-to-peer verteiltes System beschreibt ein Cluster, bestehend aus mehreren gleichberechtigten Knoten.  
\item Jeder Knoten ist in so einem Cluster dezentral, unabhängig und akzeptiert sowohl Schreib- als auch Leseoperationen.
\item Falls irgendeiner Knoten aus dem definierten Cluster ausfällt, werden die Schreib- und Leseanforderungen von anderen verfügbaren Knoten bedient.
\end{itemize}
\cass\ stellt die Verfügbarkeit und Partitionstoleranz über die Konsistenz.

\paragraph{Datenmodell}
%\paragraph{\colorbox{yellow}{Datenmodell}}

Die Hauptbestandteile des Datenmodells von \cass\ veranschaulicht die Abbildung \ref{img:cassandraDataModel}.
\begin{itemize}
\item Cluster
\item Keyspace
\item Column Family
\item Row
\item Column sowie
\item Value
\end{itemize}
\begin{figure}[H]
\centering
%trim = links, unten, rechts, oben
 \includegraphics[trim = 25mm 70mm 15mm 15mm, clip, width=0.9\textwidth]{resources/cassandra/cassandraDataModel}
\caption[Datenmodell]{Datenmodell}
\label{img:cassandraDataModel}
\end{figure}
\cass\ definiert einen Datenbankserver als ein Cluster, auf dem mehrere Datenbanken (Keyspaces) angelegt werden. Eine Spaltenfamilie (Column Family) entspricht einer Tabelle und enthält Zeilen (Rows), welche mit einer eindeutigen \textit{Id} zu identifizieren sind. In Zeilen (Rows) werden die Datensätze gespeichert, wobei jede Zeile bis zu 2 Milliarden Spalten (Columns) enthalten kann. Die Spalten (Columns) dagegen enthalten jeweils ein Paar „Schlüssel-Wert“ (Key-Value-Paar). 
Um bei Leseoperationen einen effizienteren Zugriff erreichen zu können, müssen die Spalten (Columns) Super Columns definieren, indem mehrere Spalten zusammengesetzt werden.

\subsection{Spring Framework}
%\subsection{\colorbox{yellow}{Spring Framework}}

Das Spring Framework ist ein Open Source Java Framework, welches einfache Java Objekte, sogenannte Plain-Old-Java-Objects (POJO), als \textbf{Spring-Beans} verwaltet. Dabei stellt das Spring Framework unter Anderem einen \textit{Inversion of Control Container} zu Verfügung, der per \textit{Dependency Injection} abhängige Spring-Beans miteinander verknüpft und konfiguriert.

Die wesentlichen Funktionen des Spring Frameworks sind:
\begin{itemize}
	\item Plain-Old-Java-Objects basierendes Programmiermodell.
	\item Verknüpfungen durch DI über den \textit{Inversion-of-Control Container}.
\end{itemize}

%\subsubsection{\colorbox{yellow}{Module}}
\subsubsection{Module des Spring Frameworks}

Spring Framework besteht aus Modulen, die den Entwicklern unabhängig zur Verfügung stehen. Die folgenden drei Module werden für die Umsetzung der Architektur vorgeschlagen.

\begin{itemize}
	\item Spring Core Container - Das Basismodul, das den \textit{Inversion of Control Container} \cite{InAndOutOfControl} und die Funktionen für die \textit{Dependency Injection} \cite{DIinSpring} bereitstellt. Die Anwendungsobjekte existieren in einer Spring-basierten Anwendung in einem Spring Core Container \textbf{(Abb. \ref{img:container})}. Der Spring Core Container erstellt Objekte, verschaltet und konfiguriert sie. Weiterhin übernimmt der Spring Core Container die Kontrolle über den Lebenszyklus der Objekte. In der Spring Terminolgie heißen die von einem Spring-Container verwalteten Objekte \textbf{Spring-Beans} oder einfach \textbf{Beans}.

\begin{figure}[H]
\centering
\includegraphics[width=3.0in]{resources/container}
\caption[Spring Core Container für Beans]{Spring Core Container für Beans}
\label{img:container}
\end{figure}

Seit Erscheinen der Springs-Version 1.0 im Jahr 2004 müsste man den Container mit XML konfigurieren. Ausgehend von Springs-Version 2.5 im Jahr 2007 wurde der Aufwand der XML-Konfiguration in einer Spring-basierten Anwendung durch die Kombination mit @-Annotationen extrem reduziert. Mit der Springs-Version 3.0 ist es endlich möglich geworden, den Spring-Container vollständig ohne XML-Konfiguration zu erzeugen. Diese Konfiguration ohne XML-Konfiguration nennt man \textbf{Java-basierte Konfiguration}.

	\item Spring Web - Das MVC-Framework mit der Möglichkeit REST-Webanwendungen umsetzen zu können. Dazu wird das MVC-Pattern implementiert. Zusätzlich werden allgemeine Web-Technologien wie HTTP zu Verfügung gestellt.
	\item Spring Boot - Mit diesem Module können \textit{Self-Contained} Anwendungen erstellt werden. Diese Art von Anwendungen werden in einem einzelnen JAR/WAR ausgeliefert, abhängig von Konfiguration. Zusätzlich werden die Abhängigkeiten aller benötigten Bibliotheken durch Spring Boot verwaltet. \cite{spring}
	\end{itemize}

\subsubsection{Konfiguration mit Maven}
%\subsubsection{\colorbox{yellow}{Konfiguration mit Maven}}

Um Spring Framework in einer Java Anwendung verwenden zu können, müssen die entsprechenden Bibliotheken dem Java Projekt hinzugefügt werden. Listing \ref{lst:pom} zeigt ein Beispiel für eine Maven-Konfigurationsdatei \cite{maven}, in der benötigte Bibliotheken für Spring deklariert sind.

\begin{listingsboxJava}[label={lst:pom}]{myxml}{Konfiguration mit \texttt{pom.xml}}
	<!-- Spring Core Container Modul -->
	<dependency>
		<groupId>org.springframework</groupId>
		<artifactId>spring-core</artifactId>
	</dependency>

	<!-- Spring Web Modul -->
	<dependency>
		<groupId>org.springframework</groupId>
		<artifactId>spring-web</artifactId>
	</dependency>
	
	<!-- Spring Boot Starter Modul -->
	<dependency>
		<groupId>org.springframework.boot</groupId>
		<artifactId>spring-boot-starter-web</artifactId>
	</dependency>
\end{listingsboxJava}
Maven wird verwendet, um die Abhängigkeiten zu den externen Bibliotheken zu verwalten. Die benötigten Bibliotheken werden von User in der Maven- Konfigurationsdatei \texttt{pom.xml} als Abhängigkeiten (engl. \texttt{dependencies}) deklariert und das Tool lädt die Bibliotheken automatisch herunter, speichert die in einem lokalen Repository und fügt sie dann dem Projekt hinzu.

\subsection{\textit{\textbf{RE}presentational \textbf{S}tate \textbf{T}ransfer} (REST)}

\textbf{REST} ist ein Designkonzept für die Web Services. Die Daten werden in der Form von Ressourceneinheiten ausgetauscht. Jede Ressource ist eindeutig und mit einer \textit{URI} identifizierbar.

Der Zugriff auf Ressourcen erfolgt auf Basis des \textit{HTTP}\footnote{\textit{HTTP} ist ein zustandloses Protokoll zur Übertragung der Daten zwischen Web-Clients (=Browser Anwendungen) und Web-Servers. Jede neue Anfrage, die von einem Web-Client erfolgt, erfordert einen neuen Verbindungsaufbau und erneute Datenbeschaffung.}-Protokolls. Um Ressourcen lesen, aktualisieren, löschen oder anlegen zu können, werden die gängigen \textit{HTTP}-Methoden gebraucht. Diese sind:

\begin{itemize}

\item \textit{GET} - ist ein lesender Zugriff auf Daten.
\item \textit{PUT} - aktualisiert bestehende Daten.
\item \textit{DELETE} - löscht vorhandene Daten.
\item \textit{POST} - legt neue Daten an.

\end{itemize} 

Die Rückmeldung des Web-Servers erfolgt im \textit{JSON}-Format in Kombination mit einem Code, der zusätzlich den Status der Rückmeldung mitteilt.
\textbf{REST} ist eine beliebte Technologie, wenn es um den reinen Datenaustausch zwischen Web-Clients und Web-Servers geht. 

%\subsection{\colorbox{yellow}{AngularJS 2 - JavaScript Framework}}
\subsection{AngularJS 2 - JavaScript Framework}
Angular 2 ist ein JavaScript basiertes Frontend Framework. das die Entwicklung von so genannten \textit{Single-Page-}Anwendungen ermöglicht. In einer \textit{Single-Page-}Anwendung wird die \textit{HTML}-Seite mit dem ganzen Inhalt nur einmal geladen und die Teile davon werden dynamisch nachgeladen oder updated, z. B. als Ergebnis einer Nutzerinteraktion. Weder das Neuladen der Seite noch die Weiterleitung zu den anderen Seiten ist notwendig. Die ganzen Informationen werden auf einer Seite dargestellt. 

Bei der Entwicklung mit dem AngularJS Framework werden die \textit{HTML}-Seiten mit speziellen Tag Attributen erweitert. Diese Tag Attribute sind mit JavaScript Variablen assoziiert. Falls diese Variablen geändert werden, werden die entsprechenden Teile der Seite updated. Die entsprechenden JavaScript Variablen können z. B. infolge einer WebService-Anfrage geändert werden. 

Angular 2 ist komplett in TypeScript entwickelt worden. TypeScript ist eine JavaScript-Erweiterung, die mit der Nutzung von Interfaces, Klassen, Modulen und Vererbung eine typisierte und klassenbasierte JavaScript-Programmierung ermöglicht. \cite{typescript}

